{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T19:30:34.503417Z",
     "start_time": "2025-03-21T19:30:34.493218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: mlx_lm is not installed. If you want to use mlx_lm, please install it with `pip install mlx-lm`.\n",
      "Warning: cartesia_mlx is not installed. If you want to use cartesia_mlx, please follow the instructions in the README to install it.\n"
     ]
    }
   ],
   "source": [
    "# Misc imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Import Minions + Minions\n",
    "from minions.minions_deepresearch import MinionsDeepResearch\n",
    "from minions.minion_deepresearch import MinionDeepResearch\n",
    "\n",
    "# Import Minion Clients\n",
    "from minions.clients.ollama import OllamaClient\n",
    "from minions.clients.tokasaurus import TokasaurusClient\n",
    "from minions.clients.openai import OpenAIClient\n",
    "from minions.clients.anthropic import AnthropicClient\n",
    "from minions.clients.together import TogetherClient\n",
    "\n",
    "# Import Pydantic\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Clients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Specify structured output schema for the OllamaClient. Run this block as is! Do _NOT_ make any modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T19:30:38.670313Z",
     "start_time": "2025-03-21T19:30:38.664303Z"
    }
   },
   "outputs": [],
   "source": [
    "class StructuredLocalOutput(BaseModel):\n",
    "    explanation: str\n",
    "    citation: str | None\n",
    "    answer: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Instantiate Clients: Here we instantiate our local client to be ollama and remote client to be OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T19:30:40.414699Z",
     "start_time": "2025-03-21T19:30:40.391497Z"
    }
   },
   "outputs": [],
   "source": [
    "remote_client = OpenAIClient(model_name=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "# Option 1: Ollama\n",
    "local_client = OllamaClient(\n",
    "    model_name=\"llama3.2\",  #\"llama3.2:3b\"\n",
    "    temperature=0.0, \n",
    "    structured_output_schema=StructuredLocalOutput\n",
    ")\n",
    "\n",
    "# option 2\n",
    "# local_client = TokasaurusClient(\n",
    "#     model_name=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "#     temperature=0.0,\n",
    "#     # Structured outputs are not yet supported with tokasaurus\n",
    "#     # structured_output_schema=StructuredLocalOutput\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Minion/Minions Task\n",
    "\n",
    "- context (List[str]): context that the minions need to reason over\n",
    "- doc_metadata (str): every task is parameterized by doc_metadata which describes the \"type\" of information contained in the context\n",
    "- task (str): description of the query to be completed over the context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Set-up Communication Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T05:55:34.526475Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Option 1: Minions\n",
    "protocol = MinionsDeepResearch(local_client=local_client, remote_client=remote_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify Input Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:55:39.555536Z",
     "start_time": "2025-03-19T05:55:39.540108Z"
    }
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "MCP refers to Anthropic's MCP\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify Metadata and Task Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:55:45.753499Z",
     "start_time": "2025-03-19T05:55:45.745975Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_metadata = \"MCP introduction document\"\n",
    "\n",
    "# Define the task without explicitly providing the key values.\n",
    "task = (\n",
    "    \"Explain to me anthropic's MCP protocol.\"\n",
    ")\n",
    "\n",
    "# For testing purposes, we suggest that the correct answer is:\n",
    "suggested_final_answer = (\n",
    "    \"N/A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the protocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:56:00.845535Z",
     "start_time": "2025-03-19T05:55:48.519628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Retrieving links from SerpAPI for query...\n",
      "[INFO] Crawling pages with Firecrawl...\n",
      "[Crawling] https://www.anthropic.com/news/model-context-protocol\n",
      "[Crawling] https://docs.anthropic.com/en/docs/agents-and-tools/mcp\n",
      "[Crawling] https://www.reddit.com/r/ClaudeAI/comments/1gzv8b9/anthropics_model_context_protocol_mcp_is_way/\n",
      "[ERROR] Failed to crawl https://www.reddit.com/r/ClaudeAI/comments/1gzv8b9/anthropics_model_context_protocol_mcp_is_way/: Unexpected error during scrape URL: Status code 403. This website is no longer supported, please reach out to help@firecrawl.com for more info on how to activate it on your account. - No additional error details provided.\n",
      "[Crawling] https://medium.com/@gmsharpe/working-with-anthropics-model-context-protocol-mcp-part-1-72e3a8000407\n",
      "[INFO] Synthesizing answer with remote model...\n",
      "Round 1/5\n",
      "Attempt 1/10\n",
      "Created 1 job manifests (1 chunks, apriori requested 1 samples per chunk, 1 tasks)\n",
      "Total number of job_manifests: 1\n",
      "Sending 1 worker chats to the worker client\n",
      "The MCP protocol is not explicitly defined in the provided document excerpt. Further research and analysis would be required to determine its key principles, objectives, methodologies, frameworks, outcomes, features, innovations, ethical considerations, and guidelines.\n",
      "Attempt 1/5 response: {\n",
      "  \"explanation\": \"The document excerpt lacks explicit details about the MCP protocol, making it insufficient to answer the question.\",\n",
      "  \"feedback\": \"Look for specific details about the MCP protocol, including its principles, objectives, methodologies, frameworks, outcomes, features, innovations, ethical considerations, and guidelines.\",\n",
      "  \"decision\": \"request_additional_info\",\n",
      "  \"answer\": null,\n",
      "  \"scratchpad\": \"The MCP protocol is not explicitly defined in the provided document excerpt. Further research is needed to determine its key aspects.\"\n",
      "}\n",
      "Round 2/5\n",
      "Attempt 1/10\n",
      "Created 50 job manifests (10 chunks, apriori requested 1 samples per chunk, 5 tasks)\n",
      "Total number of job_manifests: 50\n",
      "Sending 50 worker chats to the worker client\n",
      "The MCP protocol provides guidelines for developers to follow when building agentic RAG-based applications, including the use of transparent and explainable models, fair data collection and usage practices, and user consent mechanisms.\n",
      "Attempt 1/5 response: {\n",
      "  \"explanation\": \"The gathered information provides a general overview of the MCP protocol's focus on transparency, fairness, and user consent, but lacks specific details on methodologies and unique features.\",\n",
      "  \"feedback\": \"Look for specific methodologies, frameworks, unique features, and ethical guidelines of the MCP protocol.\",\n",
      "  \"decision\": \"request_additional_info\",\n",
      "  \"answer\": null,\n",
      "  \"scratchpad\": \"The MCP protocol emphasizes guidelines for transparency, fairness, and user consent in agentic applications, aiming to standardize workflows to prevent biases. Further details are needed for a comprehensive explanation.\"\n",
      "}\n",
      "Round 3/5\n",
      "Attempt 1/10\n",
      "Created 16 job manifests (16 chunks, apriori requested 1 samples per chunk, 1 tasks)\n",
      "Total number of job_manifests: 16\n",
      "Sending 16 worker chats to the worker client\n",
      "The primary objective of MCP is to enable models to interact with their environment in a more human-like way, by taking into account context and making decisions based on relevant information. By using model observers and emphasizing the importance of context, MCP provides a framework for building agentic RAG-based applications that can adapt to changing situations.\n",
      "Attempt 1/5 response: {\n",
      "  \"explanation\": \"The gathered information provides a foundational understanding of the MCP protocol's purpose and core principles, but lacks specific details on transparency, fairness, and user consent.\",\n",
      "  \"feedback\": \"Look for details on how MCP ensures transparency, fairness, and user consent, as well as technical implementation of model observers.\",\n",
      "  \"decision\": \"request_additional_info\",\n",
      "  \"answer\": null,\n",
      "  \"scratchpad\": \"The MCP protocol is a framework for building agentic RAG-based applications, emphasizing context in decision-making and the use of model observers. It aims to enable human-like interaction with the environment. Additional details on ethical guidelines and technical implementation are needed for a comprehensive explanation.\"\n",
      "}\n",
      "Round 4/5\n",
      "Attempt 1/10\n"
     ]
    }
   ],
   "source": [
    "output = protocol(\n",
    "        task=task,\n",
    "        doc_metadata=doc_metadata,\n",
    "        context=[context],\n",
    "        max_urls=5,\n",
    "        max_rounds=5,  # you can adjust rounds as needed for testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:56:06.970452Z",
     "start_time": "2025-03-19T05:56:06.914280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic's MCP protocol is an open-source framework designed to build conversational AI models. It integrates components such as LanceDB, Anthropic's Model Context Protocol, Bedrock, and Ollama, aiming to enable intelligent and autonomous interactions. The protocol is described as a flexible and modular framework for building agentic Retrieval-Augmented Generations (RAGs), allowing developers to integrate multiple models and tools to create more complex and interactive applications. However, further details on specific methodologies, intended outcomes, and unique features are needed for a comprehensive understanding.\n"
     ]
    }
   ],
   "source": [
    "print(output['final_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Minion\n",
    "protocol = MinionDeepResearch(local_client=local_client, remote_client=remote_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "doc_metadata = \"GRPO training document\"\n",
    "\n",
    "# Define the task without explicitly providing the key values.\n",
    "task = (\n",
    "    \"What are the principles of GRPO training?\"\n",
    ")\n",
    "\n",
    "# For testing purposes, we suggest that the correct answer is:\n",
    "suggested_final_answer = (\n",
    "    \"N/A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Retrieving links from SerpAPI for query...\n",
      "[INFO] Crawling pages with Firecrawl...\n",
      "[Crawling] https://medium.com/@sahin.samia/the-math-behind-deepseek-a-deep-dive-into-group-relative-policy-optimization-grpo-8a75007491ba\n",
      "[Crawling] https://docs.predibase.com/user-guide/fine-tuning/grpo\n",
      "[Crawling] https://www.linkedin.com/pulse/grpo-game-changer-deepseeks-llms-sandeep-k-dzx2f\n",
      "[INFO] Synthesizing answer with remote model...\n",
      "Privacy is enabled:  False\n"
     ]
    }
   ],
   "source": [
    "output = protocol(\n",
    "        task=task,\n",
    "        doc_metadata=doc_metadata,\n",
    "        context=[context],\n",
    "        max_urls=5,\n",
    "        max_rounds=5,  # you can adjust rounds as needed for testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The principles of G.R.P.O. training are Growth, Results, Performance, and Optimization. Each principle focuses on different aspects of personal and professional development: Growth emphasizes continuous learning and skill-building; Results focus on achieving tangible outcomes and measuring progress; Performance prioritizes excellence and continuous improvement; and Optimization aims at maximizing efficiency, effectiveness, and productivity.\n"
     ]
    }
   ],
   "source": [
    "print(output['final_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
