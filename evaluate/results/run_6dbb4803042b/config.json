{
  "protocols": [
    "minions"
  ],
  "skip_accuracy": true,
  "use_cache": true,
  "git_auto_commit": true,
  "minions_kwargs": {
    "num_tasks_per_round": 12,
    "chunk_fn": "chunk_by_section",
    "max_chunk_size": 3000,
    "pages_per_chunk": 5,
    "max_rounds": 4,
    "num_samples_per_task": 1
  },
  "all_args": {
    "global": {
      "output_dir": "evaluate/results",
      "skip_accuracy": true,
      "use_cache": true,
      "git_auto_commit": true
    },
    "dataset": {
      "path": "/workspace/financebench",
      "pdf_dir": "/workspace/financebench/pdfs",
      "filter_numerical": true,
      "max_samples": 27,
      "sample_indices": [
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150
      ]
    },
    "models": {
      "local": {
        "name": "meta-llama/Llama-3.1-8B-Instruct",
        "temperature": 0.2,
        "num_ctx": 4096,
        "backend": "sglang",
        "sglang_base_url": "http://localhost:8000/v1",
        "generation_strategy": "single_shot",
        "beta_explanation": 1.15,
        "beta_citation": 0.77,
        "beta_answer": 1.8,
        "min_tokens_explanation": 10,
        "min_tokens_citation": 5,
        "min_tokens_answer": 3,
        "max_tokens_explanation": 200,
        "max_tokens_citation": 150,
        "max_tokens_answer": 100
      },
      "remote": {
        "name": "gpt-4o",
        "temperature": 0.0
      }
    },
    "protocols": {
      "active": [
        "minions"
      ],
      "common": {
        "max_rounds": 4,
        "num_samples_per_task": 1
      },
      "minions": {
        "num_tasks_per_round": 12,
        "chunk_fn": "chunk_by_section",
        "max_chunk_size": 3000,
        "pages_per_chunk": 5
      }
    }
  },
  "created_at": "2026-01-19T21:58:49.191240"
}